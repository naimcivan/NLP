{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0329b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/huggingface/notebooks/blob/master/transformers_doc/quicktour.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d77ba3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install transformers datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0828e65",
   "metadata": {},
   "source": [
    "# Getting started on a task with a pipeline\n",
    "The easiest way to use a pretrained model on a given task is to use pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6be69f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3df7e3",
   "metadata": {},
   "source": [
    "# Transformers provides the following tasks out of the box:\n",
    "\n",
    "Sentiment analysis: is a text positive or negative?\n",
    "\n",
    "Text generation (in English): provide a prompt and the model will generate what follows.\n",
    "\n",
    "Name entity recognition (NER): in an input sentence, label each word with the entity it represents (person, place, etc.)\n",
    "\n",
    "Question answering: provide the model with some context and a question, extract the answer from the context.\n",
    "\n",
    "Filling masked text: given a text with masked words (e.g., replaced by [MASK]), fill the blanks.\n",
    "\n",
    "Summarization: generate a summary of a long text.\n",
    "\n",
    "Translation: translate a text in another language.\n",
    "\n",
    "Feature extraction: return a tensor representation of the text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ff4d1c",
   "metadata": {},
   "source": [
    "# Let's see how this work for sentiment analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f81df47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7bc66923e054f21a4fcfa8e4f58e752",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/255M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d81c26b2e78e40fb84ec76aad12fdd8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d78aea1eb8b445a5a5a7e8bffdd293f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifier = pipeline('sentiment-analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16bae2b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9997795224189758}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier('We are very happy to show you the ðŸ¤— Transformers library.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "216a686d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: POSITIVE, with score: 0.9998\n",
      "label: NEGATIVE, with score: 0.5309\n"
     ]
    }
   ],
   "source": [
    "results = classifier([\"We are very happy to show you the ðŸ¤— Transformers library.\",\n",
    "           \"We hope you don't hate it.\"])\n",
    "for result in results:\n",
    "    print(f\"label: {result['label']}, with score: {round(result['score'], 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a0e4d0",
   "metadata": {},
   "source": [
    "Let's say we want to use another model; for instance, one that has been trained on French data. We can search through the model hub that gathers models pretrained on a lot of data by research labs, but also community models (usually fine-tuned versions of those big models on a specific dataset). Applying the tags \"French\" and \"text-classification\" gives back a suggestion \"nlptown/bert-base-multilingual-uncased-sentiment\". Let's see how we can use it.\n",
    "\n",
    "You can directly pass the name of the model to use to pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "295659a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier = pipeline('sentiment-analysis', model=\"nlptown/bert-base-multilingual-uncased-sentiment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8cdd8f",
   "metadata": {},
   "source": [
    "This classifier can now deal with texts in English, French, but also Dutch, German, Italian and Spanish! You can also replace that name by a local folder where you have saved a pretrained model (see below). You can also pass a model object and its associated tokenizer.\n",
    "\n",
    "We will need two classes for this. The first is AutoTokenizer, which we will use to download the tokenizer associated to the model we picked and instantiate it. The second is AutoModelForSequenceClassification (or TFAutoModelForSequenceClassification if you are using TensorFlow), which we will use to download the model itself. Note that if we were using the library on an other task, the class of the model would change. The task summary tutorial summarizes which class is used for which task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6923b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PYTORCH CODE\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99db89f3",
   "metadata": {},
   "source": [
    "Now, to download the models and tokenizer we found previously, we just have to use the AutoModelForSequenceClassification.from_pretrained method (feel free to replace model_name by any other model from the model hub):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7f359ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef953a02bdd54ce186e0b18677e5fd68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/953 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ed940b00a6542af91584b631a4baff7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/638M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d0d291b07874df392d73240db48a58d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/39.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b07fd3bb7a91410bb675cb9755abbe88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/851k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62ca8a948d3a4409ab0708d743df4cf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## PYTORCH CODE\n",
    "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "classifier = pipeline('sentiment-analysis', model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28060169",
   "metadata": {},
   "source": [
    "If you don't find a model that has been pretrained on some data similar to yours, you will need to fine-tune a pretrained model on your data. We provide example scripts to do so. Once you're done, don't forget to share your fine-tuned model on the hub with the community, using this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94823f56",
   "metadata": {},
   "source": [
    "# Under the hood: pretrained models\n",
    "Let's now see what happens beneath the hood when using those pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e688a4f",
   "metadata": {},
   "source": [
    "As we saw, the model and tokenizer are created using the from_pretrained method:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bf4af8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PYTORCH CODE\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "pt_model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33266020",
   "metadata": {},
   "source": [
    "# Using the tokenizer\n",
    "We mentioned the tokenizer is responsible for the preprocessing of your texts. First, it will split a given text in words (or part of words, punctuation symbols, etc.) usually called tokens. There are multiple rules that can govern that process (you can learn more about them in the tokenizer summary), which is why we need to instantiate the tokenizer using the name of the model, to make sure we use the same rules as when the model was pretrained.\n",
    "\n",
    "The second step is to convert those tokens into numbers, to be able to build a tensor out of them and feed them to the model. To do this, the tokenizer has a vocab, which is the part we download when we instantiate it with the from_pretrained method, since we need to use the same vocab as when the model was pretrained.\n",
    "\n",
    "To apply these steps on a given text, we can just feed it to our tokenizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "718bf5f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 2057, 2024, 2200, 3407, 2000, 2265, 2017, 1996, 100, 19081, 3075, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(\"We are very happy to show you the ðŸ¤— Transformers library.\")\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6dfb86",
   "metadata": {},
   "source": [
    "This returns a dictionary string to list of ints. It contains the ids of the tokens, as mentioned before, but also additional arguments that will be useful to the model. Here for instance, we also have an attention mask that the model will use to have a better understanding of the sequence:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd0a830",
   "metadata": {},
   "source": [
    "You can pass a list of sentences directly to your tokenizer. If your goal is to send them through your model as a batch, you probably want to pad them all to the same length, truncate them to the maximum length the model can accept and get tensors back. You can specify all of that to the tokenizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89ab87b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PYTORCH CODE\n",
    "pt_batch = tokenizer(\n",
    "    [\"We are very happy to show you the ðŸ¤— Transformers library.\", \"We hope you don't hate it.\"],\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=512,\n",
    "    return_tensors=\"pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6853a271",
   "metadata": {},
   "source": [
    "The padding is automatically applied on the side expected by the model (in this case, on the right), with the padding token the model was pretrained with. The attention mask is also adapted to take the padding into account:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6eb5fe5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids: [[101, 2057, 2024, 2200, 3407, 2000, 2265, 2017, 1996, 100, 19081, 3075, 1012, 102], [101, 2057, 3246, 2017, 2123, 1005, 1056, 5223, 2009, 1012, 102, 0, 0, 0]]\n",
      "attention_mask: [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "## PYTORCH CODE\n",
    "for key, value in pt_batch.items():\n",
    "    print(f\"{key}: {value.numpy().tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3ac332",
   "metadata": {},
   "source": [
    "# Using the model\n",
    "Once your input has been preprocessed by the tokenizer, you can send it directly to the model. As we mentioned, it will contain all the relevant information the model needs. If you're using a TensorFlow model, you can pass the dictionary keys directly to tensors, for a PyTorch model, you need to unpack the dictionary by adding **."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a7ff372",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PYTORCH CODE\n",
    "pt_outputs = pt_model(**pt_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e0c0b2",
   "metadata": {},
   "source": [
    "In ðŸ¤— Transformers, all outputs are objects that contain the model's final activations along with other metadata. These objects are described in greater detail here. For now, let's inspect the output ourselves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "457caabc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequenceClassifierOutput(loss=None, logits=tensor([[-4.0833,  4.3364],\n",
      "        [ 0.0818, -0.0418]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n"
     ]
    }
   ],
   "source": [
    "## PYTORCH CODE\n",
    "print(pt_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8426cf3",
   "metadata": {},
   "source": [
    "####  Notice how the output object has a logits attribute. You can use this to access the model's final activations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a754ab",
   "metadata": {},
   "source": [
    "# NOTE: \n",
    "All ðŸ¤— Transformers models (PyTorch or TensorFlow) return the activations of the model before the final activation function (like SoftMax) since this final activation function is often fused with the loss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3f1d4d",
   "metadata": {},
   "source": [
    "Let's apply the SoftMax activation to get predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed897a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PYTORCH CODE\n",
    "from torch import nn\n",
    "pt_predictions = nn.functional.softmax(pt_outputs.logits, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "89a3eb8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.2043e-04, 9.9978e-01],\n",
      "        [5.3086e-01, 4.6914e-01]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# We can see we get the numbers from before:\n",
    "\n",
    "## PYTORCH CODE\n",
    "print(pt_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1b6345",
   "metadata": {},
   "source": [
    "If you provide the model with labels in addition to inputs, the model output object will also contain a loss attribute:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e206b588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequenceClassifierOutput(loss=tensor(0.3167, grad_fn=<NllLossBackward0>), logits=tensor([[-4.0833,  4.3364],\n",
      "        [ 0.0818, -0.0418]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n"
     ]
    }
   ],
   "source": [
    "## PYTORCH CODE\n",
    "import torch\n",
    "pt_outputs = pt_model(**pt_batch, labels = torch.tensor([1, 0]))\n",
    "print(pt_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ec3847",
   "metadata": {},
   "source": [
    "Models are standard torch.nn.Module or tf.keras.Model so you can use them in your usual training loop. ðŸ¤— Transformers also provides a Trainer class to help with your training (taking care of things such as distributed training, mixed precision, etc.). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79394a7",
   "metadata": {},
   "source": [
    "# NOTE: \n",
    "Pytorch model outputs are special dataclasses so that you can get autocompletion for their attributes in an IDE. They also behave like a tuple or a dictionary (e.g., you can index with an integer, a slice or a string) in which case the attributes not set (that have None values) are ignored."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6559fdf",
   "metadata": {},
   "source": [
    "Once your model is fine-tuned, you can save it with its tokenizer in the following way:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c1e37796",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_directory = \"Desktop\"\n",
    "tokenizer.save_pretrained(save_directory)\n",
    "model.save_pretrained(save_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4898dd6",
   "metadata": {},
   "source": [
    "You can then load this model back using the AutoModel.from_pretrained method by passing the directory name instead of the model name. One cool feature of ðŸ¤— Transformers is that you can easily switch between PyTorch and TensorFlow: any model saved as before can be loaded back either in PyTorch or TensorFlow. If you are loading a saved PyTorch model in a TensorFlow model, use TFAutoModel.from_pretrained.\n",
    "\n",
    "and if you are loading a saved TensorFlow model in a PyTorch model, you should use the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c9fdf7cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Desktop were not used when initializing BertModel: ['classifier.weight', 'classifier.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel\n",
    "tokenizer = AutoTokenizer.from_pretrained(save_directory)\n",
    "model = AutoModel.from_pretrained(save_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f765d28f",
   "metadata": {},
   "source": [
    "Lastly, you can also ask the model to return all hidden states and all attention weights if you need them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9cabc93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PYTORCH CODE\n",
    "pt_outputs = pt_model(**pt_batch, output_hidden_states=True, output_attentions=True)\n",
    "all_hidden_states  = pt_outputs.hidden_states \n",
    "all_attentions = pt_outputs.attentions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60bd824",
   "metadata": {},
   "source": [
    "# Accessing the code\n",
    "The AutoModel and AutoTokenizer classes are just shortcuts that will automatically work with any pretrained model. Behind the scenes, the library has one model class per combination of architecture plus class, so the code is easy to access and tweak if you need to.\n",
    "\n",
    "In our previous example, the model was called \"distilbert-base-uncased-finetuned-sst-2-english\", which means it's using the DistilBERT architecture. As AutoModelForSequenceClassification was used, the model automatically created is then a DistilBertForSequenceClassification. You can look at its documentation for all details relevant to that specific model, or browse the source code. This is how you would directly instantiate model and tokenizer without the auto magic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2a6e7534",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PYTORCH CODE\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "model = DistilBertForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32965817",
   "metadata": {},
   "source": [
    "# Customizing the model\n",
    "If you want to change how the model itself is built, you can define a custom configuration class. Each architecture comes with its own relevant configuration. For example, DistilBertConfig allows you to specify parameters such as the hidden dimension, dropout rate, etc for DistilBERT. If you do core modifications, like changing the hidden size, you won't be able to use a pretrained model anymore and will need to train from scratch. You would then instantiate the model directly from this configuration.\n",
    "\n",
    "Below, we load a predefined vocabulary for a tokenizer with the DistilBertTokenizer.from_pretrained method. However, unlike the tokenizer, we wish to initialize the model from scratch. Therefore, we instantiate the model from a configuration instead of using the DistilBertForSequenceClassification.from_pretrained method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "58a90695",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb539b0aed6e46219b81d2a6af09e23d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7f01d5f88754dcabdb2c789dd5c5d9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9aa59263aa4473099e08ec1dddf43a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d594aa45dc054d1fbb9d566534c41cb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## PYTORCH CODE\n",
    "from transformers import DistilBertConfig, DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "config = DistilBertConfig(n_heads=8, dim=512, hidden_dim=4*512)\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertForSequenceClassification(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0632fc35",
   "metadata": {},
   "source": [
    "For something that only changes the head of the model (for instance, the number of labels), you can still use a pretrained model for the body. For instance, let's define a classifier for 10 different labels using a pretrained body. Instead of creating a new configuration with all the default values just to change the number of labels, we can instead pass any argument a configuration would take to the from_pretrained method and it will update the default configuration appropriately:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2227a90e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c0d46bb984644fb908ddc91fbc8001a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/256M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "## PYTORCH CODE\n",
    "from transformers import DistilBertConfig, DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "model = DistilBertForSequenceClassification.from_pretrained(model_name, num_labels=10)\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5c369d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45b9109",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4277cd70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4066925d",
   "metadata": {},
   "source": [
    "# Summary of the tasks\n",
    "This page shows the most frequent use-cases when using the library. The models available allow for many different configurations and a great versatility in use-cases. The most simple ones are presented here, showcasing usage for tasks such as question answering, sequence classification, named entity recognition and others.\n",
    "\n",
    "These examples leverage auto-models, which are classes that will instantiate a model according to a given checkpoint, automatically selecting the correct model architecture. Please check the AutoModel documentation for more information. Feel free to modify the code to be more specific and adapt it to your specific use-case.\n",
    "\n",
    "In order for a model to perform well on a task, it must be loaded from a checkpoint corresponding to that task. These checkpoints are usually pre-trained on a large corpus of data and fine-tuned on a specific task. This means the following:\n",
    "\n",
    "Not all models were fine-tuned on all tasks. If you want to fine-tune a model on a specific task, you can leverage one of the run_$TASK.py scripts in the examples directory.\n",
    "Fine-tuned models were fine-tuned on a specific dataset. This dataset may or may not overlap with your use-case and domain. As mentioned previously, you may leverage the examples scripts to fine-tune your model, or you may create your own training script.\n",
    "In order to do an inference on a task, several mechanisms are made available by the library:\n",
    "\n",
    "Pipelines: very easy-to-use abstractions, which require as little as two lines of code.\n",
    "Direct model use: Less abstractions, but more flexibility and power via a direct access to a tokenizer (PyTorch/TensorFlow) and full inference capacity.\n",
    "Both approaches are showcased here.\n",
    "\n",
    "#### NOTE: \n",
    "All tasks presented here leverage pre-trained checkpoints that were fine-tuned on specific tasks. Loading a checkpoint that was not fine-tuned on a specific task would load only the base transformer layers and not the additional head that is used for the task, initializing the weights of that head randomly.\n",
    "\n",
    "This would produce random output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de64749",
   "metadata": {},
   "source": [
    "# Sequence Classification\n",
    "Sequence classification is the task of classifying sequences according to a given number of classes. An example of sequence classification is the GLUE dataset, which is entirely based on that task. If you would like to fine-tune a model on a GLUE sequence classification task, you may leverage the :prefix_link:*run_glue.py\n",
    "\n",
    "<examples/pytorch/text-classification/run_glue.py>, :prefix_link:run_tf_glue.py\n",
    "\n",
    "<examples/tensorflow/text-classification/run_tf_glue.py>, :prefix_link:run_tf_text_classification.py\n",
    "\n",
    "<examples/tensorflow/text-classification/run_tf_text_classification.py> or :prefix_link:run_xnli.py\n",
    "\n",
    "<examples/pytorch/text-classification/run_xnli.py>* scripts.\n",
    "\n",
    "Here is an example of using pipelines to do sentiment analysis: identifying if a sequence is positive or negative. It leverages a fine-tuned model on sst2, which is a GLUE task.\n",
    "\n",
    "This returns a label (\"POSITIVE\" or \"NEGATIVE\") alongside a score, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1f432345",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: NEGATIVE, with score: 0.9991\n",
      "label: POSITIVE, with score: 0.9999\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "result = classifier(\"I hate you\")[0]\n",
    "print(f\"label: {result['label']}, with score: {round(result['score'], 4)}\")\n",
    "result = classifier(\"I love you\")[0]\n",
    "print(f\"label: {result['label']}, with score: {round(result['score'], 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9144bd",
   "metadata": {},
   "source": [
    "Here is an example of doing a sequence classification using a model to determine if two sequences are paraphrases of each other. The process is the following:\n",
    "\n",
    "1. Instantiate a tokenizer and a model from the checkpoint name. The model is identified as a BERT model and loads it with the weights stored in the checkpoint.\n",
    "\n",
    "2. Build a sequence from the two sentences, with the correct model-specific separators, token type ids and attention masks (which will be created automatically by the tokenizer).\n",
    "\n",
    "3. Pass this sequence through the model so that it is classified in one of the two available classes: 0 (not a paraphrase) and 1 (is a paraphrase).\n",
    "\n",
    "4. Compute the softmax of the result to get probabilities over the classes.\n",
    "\n",
    "5. Print the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "facdc0c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "037b39cb80324c35ac6e75a8278059b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f700cda69d048ff98e5a9b7b7260d4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/433 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8a411cf1a2144e1896ea6531a87d9ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/208k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3075166a71fe4605a11e5222bd26625f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/426k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c857f514a964192a8f75152857789f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/413M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not paraphrase: 10%\n",
      "is paraphrase: 90%\n",
      "not paraphrase: 94%\n",
      "is paraphrase: 6%\n"
     ]
    }
   ],
   "source": [
    "## PYTORCH CODE\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased-finetuned-mrpc\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased-finetuned-mrpc\")\n",
    "classes = [\"not paraphrase\", \"is paraphrase\"]\n",
    "sequence_0 = \"The company HuggingFace is based in New York City\"\n",
    "sequence_1 = \"Apples are especially bad for your health\"\n",
    "sequence_2 = \"HuggingFace's headquarters are situated in Manhattan\"\n",
    "# The tokekenizer will automatically add any model specific separators (i.e. <CLS> and <SEP>) and tokens to the sequence, as well as compute the attention masks.\n",
    "paraphrase = tokenizer(sequence_0, sequence_2, return_tensors=\"pt\")\n",
    "not_paraphrase = tokenizer(sequence_0, sequence_1, return_tensors=\"pt\")\n",
    "paraphrase_classification_logits = model(**paraphrase).logits\n",
    "not_paraphrase_classification_logits = model(**not_paraphrase).logits\n",
    "paraphrase_results = torch.softmax(paraphrase_classification_logits, dim=1).tolist()[0]\n",
    "not_paraphrase_results = torch.softmax(not_paraphrase_classification_logits, dim=1).tolist()[0]\n",
    "# Should be paraphrase\n",
    "for i in range(len(classes)):\n",
    "    print(f\"{classes[i]}: {int(round(paraphrase_results[i] * 100))}%\")\n",
    "# Should not be paraphrase\n",
    "for i in range(len(classes)):\n",
    "    print(f\"{classes[i]}: {int(round(not_paraphrase_results[i] * 100))}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48f25ad",
   "metadata": {},
   "source": [
    "# Extractive Question Answering\n",
    "Extractive Question Answering is the task of extracting an answer from a text given a question. An example of a question answering dataset is the SQuAD dataset, which is entirely based on that task. If you would like to fine-tune a model on a SQuAD task, you may leverage the run_qa.py and run_tf_squad.py scripts.\n",
    "\n",
    "Here is an example of using pipelines to do question answering: extracting an answer from a text given a question. It leverages a fine-tuned model on SQuAD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "09afa664",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-cased-distilled-squad (https://huggingface.co/distilbert-base-cased-distilled-squad)\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "question_answerer = pipeline(\"question-answering\")\n",
    "context = r\"\"\"\n",
    "Extractive Question Answering is the task of extracting an answer from a text given a question. An example of a\n",
    "question answering dataset is the SQuAD dataset, which is entirely based on that task. If you would like to fine-tune\n",
    "a model on a SQuAD task, you may leverage the examples/pytorch/question-answering/run_squad.py script.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ffb481",
   "metadata": {},
   "source": [
    "This returns an answer extracted from the text, a confidence score, alongside \"start\" and \"end\" values, which are the positions of the extracted answer in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "00159a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 'the task of extracting an answer from a text given a question', score: 0.6177, start: 34, end: 95\n",
      "Answer: 'SQuAD dataset', score: 0.5152, start: 147, end: 160\n"
     ]
    }
   ],
   "source": [
    "result = question_answerer(question=\"What is extractive question answering?\", context=context)\n",
    "print(f\"Answer: '{result['answer']}', score: {round(result['score'], 4)}, start: {result['start']}, end: {result['end']}\")\n",
    "result = question_answerer(question=\"What is a good example of a question answering dataset?\", context=context)\n",
    "print(f\"Answer: '{result['answer']}', score: {round(result['score'], 4)}, start: {result['start']}, end: {result['end']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba001ced",
   "metadata": {},
   "source": [
    "#### Here is an example of question answering using a model and a tokenizer. The process is the following:\n",
    "\n",
    "1. Instantiate a tokenizer and a model from the checkpoint name. The model is identified as a BERT model and loads it with the weights stored in the checkpoint.\n",
    "\n",
    "2. Define a text and a few questions.\n",
    "\n",
    "3. Iterate over the questions and build a sequence from the text and the current question, with the correct model-specific separators token type ids and attention masks.\n",
    "\n",
    "4. Pass this sequence through the model. This outputs a range of scores across the entire sequence tokens (question and text), for both the start and end positions.\n",
    "\n",
    "5. Compute the softmax of the result to get probabilities over the tokens.\n",
    "\n",
    "6. Fetch the tokens from the identified start and stop values, convert those tokens to a string.\n",
    "\n",
    "7. Print the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ca45a8f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49ae596b8a624f399ea64ec4eff17b83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf5ab14f3d6f439193839f6683533046",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/443 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d3c92a7f3324b7fa3ddfa96369ece78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ce7bf3d7fa14df488b95f433ed06867",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f35dc870cd3c4f86bfd6e9b17ced9585",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.25G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many pretrained models are available in ðŸ¤— Transformers?\n",
      "Answer: over 32 +\n",
      "Question: What does ðŸ¤— Transformers provide?\n",
      "Answer: general - purpose architectures\n",
      "Question: ðŸ¤— Transformers provides interoperability between which frameworks?\n",
      "Answer: tensorflow 2. 0 and pytorch\n"
     ]
    }
   ],
   "source": [
    "## PYTORCH CODE\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "import torch\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-large-uncased-whole-word-masking-finetuned-squad\")\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\"bert-large-uncased-whole-word-masking-finetuned-squad\")\n",
    "text = r\"\"\"\n",
    "ðŸ¤— Transformers (formerly known as pytorch-transformers and pytorch-pretrained-bert) provides general-purpose\n",
    "architectures (BERT, GPT-2, RoBERTa, XLM, DistilBert, XLNetâ€¦) for Natural Language Understanding (NLU) and Natural\n",
    "Language Generation (NLG) with over 32+ pretrained models in 100+ languages and deep interoperability between\n",
    "TensorFlow 2.0 and PyTorch.\n",
    "\"\"\"\n",
    "questions = [\n",
    "    \"How many pretrained models are available in ðŸ¤— Transformers?\",\n",
    "    \"What does ðŸ¤— Transformers provide?\",\n",
    "    \"ðŸ¤— Transformers provides interoperability between which frameworks?\",\n",
    "]\n",
    "for question in questions:\n",
    "    inputs = tokenizer(question, text, add_special_tokens=True, return_tensors=\"pt\")\n",
    "    input_ids = inputs[\"input_ids\"].tolist()[0]\n",
    "\n",
    "    outputs = model(**inputs)\n",
    "    answer_start_scores = outputs.start_logits\n",
    "    answer_end_scores = outputs.end_logits\n",
    "\n",
    "    answer_start = torch.argmax(\n",
    "        answer_start_scores\n",
    "    )  # Get the most likely beginning of answer with the argmax of the score\n",
    "    answer_end = torch.argmax(answer_end_scores) + 1  # Get the most likely end of answer with the argmax of the score\n",
    "\n",
    "    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end]))\n",
    "\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df3e59d",
   "metadata": {},
   "source": [
    "# Language Modeling\n",
    "Language modeling is the task of fitting a model to a corpus, which can be domain specific. All popular transformer-based models are trained using a variant of language modeling, e.g. BERT with masked language modeling, GPT-2 with causal language modeling.\n",
    "\n",
    "Language modeling can be useful outside of pretraining as well, for example to shift the model distribution to be domain-specific: using a language model trained over a very large corpus, and then fine-tuning it to a news dataset or on scientific papers e.g. LysandreJik/arxiv-nlp."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17414feb",
   "metadata": {},
   "source": [
    "# Masked Language Modeling\n",
    "Masked language modeling is the task of masking tokens in a sequence with a masking token, and prompting the model to fill that mask with an appropriate token. This allows the model to attend to both the right context (tokens on the right of the mask) and the left context (tokens on the left of the mask). Such a training creates a strong basis for downstream tasks requiring bi-directional context, such as SQuAD (question answering, see Lewis, Lui, Goyal et al., part 4.2). If you would like to fine-tune a model on a masked language modeling task, you may leverage the :prefix_link:run_mlm.py <examples/pytorch/language-modeling/run_mlm.py> script.\n",
    "\n",
    "Here is an example of using pipelines to replace a mask from a sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "261d5391",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilroberta-base (https://huggingface.co/distilroberta-base)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f442c7bbd564cbaab70a148117abdc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/480 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aab6800cc57740be80da18a750175983",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/316M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c52d60b220c94a169e9c181d64a2b5b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b729b354f34e4fe89d9d36eea3975bfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "936a79d346244cce9b49ac54b4159258",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "unmasker = pipeline(\"fill-mask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cc5a1759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'score': 0.17927508056163788,\n",
      "  'sequence': 'HuggingFace is creating a tool that the community uses to solve '\n",
      "              'NLP tasks.',\n",
      "  'token': 3944,\n",
      "  'token_str': ' tool'},\n",
      " {'score': 0.11349443346261978,\n",
      "  'sequence': 'HuggingFace is creating a framework that the community uses to '\n",
      "              'solve NLP tasks.',\n",
      "  'token': 7208,\n",
      "  'token_str': ' framework'},\n",
      " {'score': 0.05243544280529022,\n",
      "  'sequence': 'HuggingFace is creating a library that the community uses to '\n",
      "              'solve NLP tasks.',\n",
      "  'token': 5560,\n",
      "  'token_str': ' library'},\n",
      " {'score': 0.0349353663623333,\n",
      "  'sequence': 'HuggingFace is creating a database that the community uses to '\n",
      "              'solve NLP tasks.',\n",
      "  'token': 8503,\n",
      "  'token_str': ' database'},\n",
      " {'score': 0.028602443635463715,\n",
      "  'sequence': 'HuggingFace is creating a prototype that the community uses to '\n",
      "              'solve NLP tasks.',\n",
      "  'token': 17715,\n",
      "  'token_str': ' prototype'}]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(unmasker(f\"HuggingFace is creating a {unmasker.tokenizer.mask_token} that the community uses to solve NLP tasks.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a27e5c2",
   "metadata": {},
   "source": [
    "#### Here is an example of doing masked language modeling using a model and a tokenizer. The process is the following:\n",
    "\n",
    "1. Instantiate a tokenizer and a model from the checkpoint name. The model is identified as a DistilBERT model and loads it with the weights stored in the checkpoint.\n",
    "\n",
    "2. Define a sequence with a masked token, placing the tokenizer.mask_token instead of a word.\n",
    "\n",
    "3. Encode that sequence into a list of IDs and find the position of the masked token in that list.\n",
    "\n",
    "4. Retrieve the predictions at the index of the mask token: this tensor has the same size as the vocabulary, and the values are the scores attributed to each token. The model gives higher score to tokens it deems probable in that context.\n",
    "\n",
    "5. Retrieve the top 5 tokens using the PyTorch topk or TensorFlow top_k methods.\n",
    "\n",
    "6. Replace the mask token by the tokens and print the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6c746d71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c881ad05e184ec8a20cb39efd40654a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71d872df81cb4ccaa9beeb8a3c9580ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/411 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6acf60f875c4afba4c009d6d2afa5a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/208k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0919e0f50474be98919be0a5f97f971",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/426k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Naim Cavin\\anaconda3\\lib\\site-packages\\transformers\\models\\auto\\modeling_auto.py:694: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bdc8bbbd6624d929a9c2948495d6926",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/251M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## PYTORCH CODE\n",
    "from transformers import AutoModelWithLMHead, AutoTokenizer\n",
    "import torch\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-cased\")\n",
    "model = AutoModelWithLMHead.from_pretrained(\"distilbert-base-cased\")\n",
    "sequence = f\"Distilled models are smaller than the models they mimic. Using them instead of the large versions would help {tokenizer.mask_token} our carbon footprint.\"\n",
    "input = tokenizer.encode(sequence, return_tensors=\"pt\")\n",
    "mask_token_index = torch.where(input == tokenizer.mask_token_id)[1]\n",
    "token_logits = model(input).logits\n",
    "mask_token_logits = token_logits[0, mask_token_index, :]\n",
    "top_5_tokens = torch.topk(mask_token_logits, 5, dim=1).indices[0].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4722934c",
   "metadata": {},
   "source": [
    "#### This prints five sequences, with the top 5 tokens predicted by the model:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "32bbbb31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distilled models are smaller than the models they mimic. Using them instead of the large versions would help reduce our carbon footprint.\n",
      "Distilled models are smaller than the models they mimic. Using them instead of the large versions would help increase our carbon footprint.\n",
      "Distilled models are smaller than the models they mimic. Using them instead of the large versions would help decrease our carbon footprint.\n",
      "Distilled models are smaller than the models they mimic. Using them instead of the large versions would help offset our carbon footprint.\n",
      "Distilled models are smaller than the models they mimic. Using them instead of the large versions would help improve our carbon footprint.\n"
     ]
    }
   ],
   "source": [
    "for token in top_5_tokens:\n",
    "    print(sequence.replace(tokenizer.mask_token, tokenizer.decode([token])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c832bc2e",
   "metadata": {},
   "source": [
    "# Causal Language Modeling\n",
    "Causal language modeling is the task of predicting the token following a sequence of tokens. In this situation, the model only attends to the left context (tokens on the left of the mask). Such a training is particularly interesting for generation tasks. If you would like to fine-tune a model on a causal language modeling task, you may leverage the :prefix_link:run_clm.py <examples/pytorch/language-modeling/run_clm.py> script.\n",
    "\n",
    "Usually, the next token is predicted by sampling from the logits of the last hidden state the model produces from the input sequence.\n",
    "\n",
    "Here is an example of using the tokenizer and model and leveraging the PreTrainedModel.top_k_top_p_filtering method to sample the next token following an input sequence of tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2a243df7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09992c6c2f7d49cbac49d7598efedd86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2584f7e7207b4e80a137ec7472d1935d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/0.99M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65cc90186c3a44d5ae2881e8977f7640",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f534c80736147c196536ef0d14127f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a7b3cdb89e645708047f5914864b682",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/523M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## PYTORCH CODE\n",
    "from transformers import AutoModelWithLMHead, AutoTokenizer, top_k_top_p_filtering\n",
    "import torch\n",
    "from torch import nn\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "model = AutoModelWithLMHead.from_pretrained(\"gpt2\")\n",
    "sequence = f\"Hugging Face is based in DUMBO, New York City, and\"\n",
    "input_ids = tokenizer.encode(sequence, return_tensors=\"pt\")\n",
    "# get logits of last hidden state\n",
    "next_token_logits = model(input_ids).logits[:, -1, :]\n",
    "# filter\n",
    "filtered_next_token_logits = top_k_top_p_filtering(next_token_logits, top_k=50, top_p=1.0)\n",
    "# sample\n",
    "probs = nn.functional.softmax(filtered_next_token_logits, dim=-1)\n",
    "next_token = torch.multinomial(probs, num_samples=1)\n",
    "generated = torch.cat([input_ids, next_token], dim=-1)\n",
    "resulting_string = tokenizer.decode(generated.tolist()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cba98cf",
   "metadata": {},
   "source": [
    "This outputs a (hopefully) coherent next token following the original sequence, which in our case is the word has:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6f02b228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face is based in DUMBO, New York City, and features\n"
     ]
    }
   ],
   "source": [
    "print(resulting_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1d61a4",
   "metadata": {},
   "source": [
    "# Text Generation\n",
    "In text generation (a.k.a open-ended text generation) the goal is to create a coherent portion of text that is a continuation from the given context. The following example shows how GPT-2 can be used in pipelines to generate text. As a default all models apply Top-K sampling when used in pipelines, as configured in their respective configurations (see gpt-2 config for example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e4512d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to gpt2 (https://huggingface.co/gpt2)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'As far as I am concerned, I will be the first to admit that I am not a fan of the idea of a \"free market.\" I think that the idea of a free market is a bit of a stretch. I think that the idea'}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "text_generator = pipeline(\"text-generation\")\n",
    "print(text_generator(\"As far as I am concerned, I will\", max_length=50, do_sample=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7df178a",
   "metadata": {},
   "source": [
    "Here, the model generates a random text with a total maximal length of 50 tokens from context \"As far as I am concerned, I will\". Behind the scenes, the pipeline object calls the method PreTrainedModel.generate to generate text. The default arguments for this method can be overridden in the pipeline, as is shown above for the arguments max_length and do_sample.\n",
    "\n",
    "Below is an example of text generation using XLNet and its tokenizer, which includes calling generate directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "92d360c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cae48412c00446ab4f0a145a1d41bef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/760 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8344f5137ea0474989f146bc1642e92f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/445M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd3cbca46b0f4359bfe59b3faa15ba10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/779k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83fca663e2ae411a818709810e14d389",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.32M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## PYTORCH CODE\n",
    "from transformers import AutoModelWithLMHead, AutoTokenizer\n",
    "model = AutoModelWithLMHead.from_pretrained(\"xlnet-base-cased\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"xlnet-base-cased\")\n",
    "# Padding text helps XLNet with short prompts - proposed by Aman Rusia in https://github.com/rusiaaman/XLNet-gen#methodology\n",
    "PADDING_TEXT = \"\"\"In 1991, the remains of Russian Tsar Nicholas II and his family\n",
    "(except for Alexei and Maria) are discovered.\n",
    "The voice of Nicholas's young son, Tsarevich Alexei Nikolaevich, narrates the\n",
    "remainder of the story. 1883 Western Siberia,\n",
    "a young Grigori Rasputin is asked by his father and a group of men to perform magic.\n",
    "Rasputin has a vision and denounces one of the men as a horse thief. Although his\n",
    "father initially slaps him for making such an accusation, Rasputin watches as the\n",
    "man is chased outside and beaten. Twenty years later, Rasputin sees a vision of\n",
    "the Virgin Mary, prompting him to become a priest. Rasputin quickly becomes famous,\n",
    "with people, even a bishop, begging for his blessing. <eod> </s> <eos>\"\"\"\n",
    "prompt = \"Today the weather is really nice and I am planning on \"\n",
    "inputs = tokenizer.encode(PADDING_TEXT + prompt, add_special_tokens=False, return_tensors=\"pt\")\n",
    "prompt_length = len(tokenizer.decode(inputs[0], skip_special_tokens=True, clean_up_tokenization_spaces=True))\n",
    "outputs = model.generate(inputs, max_length=250, do_sample=True, top_p=0.95, top_k=60)\n",
    "generated = prompt + tokenizer.decode(outputs[0])[prompt_length:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3a19cd6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today the weather is really nice and I am planning on anning on going to an incredible event in the future. As I wrote yesterday, I saw this video that we were on Sunday, but today it is beautiful to listen and watch in the heat of the day. It is kind of a pleasure to see other people and watch the scene in motion with you in it. But I still love being a fan of it. I can do\n"
     ]
    }
   ],
   "source": [
    "print(generated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d9b9d3",
   "metadata": {},
   "source": [
    "Text generation is currently possible with GPT-2, OpenAi-GPT, CTRL, XLNet, Transfo-XL and Reformer in PyTorch and for most models in Tensorflow as well. As can be seen in the example above XLNet and Transfo-XL often need to be padded to work well. GPT-2 is usually a good choice for open-ended text generation because it was trained on millions of webpages with a causal language modeling objective.\n",
    "\n",
    "For more information on how to apply different decoding strategies for text generation, please also refer to our text generation blog post here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e292d013",
   "metadata": {},
   "source": [
    "# Named Entity Recognition\n",
    "Named Entity Recognition (NER) is the task of classifying tokens according to a class, for example, identifying a token as a person, an organisation or a location. An example of a named entity recognition dataset is the CoNLL-2003 dataset, which is entirely based on that task. If you would like to fine-tune a model on an NER task, you may leverage the :prefix_link:run_ner.py <examples/pytorch/token-classification/run_ner.py> script.\n",
    "\n",
    "Here is an example of using pipelines to do named entity recognition, specifically, trying to identify tokens as belonging to one of 9 classes:\n",
    "\n",
    "O, Outside of a named entity\n",
    "\n",
    "B-MIS, Beginning of a miscellaneous entity right after another miscellaneous entity\n",
    "\n",
    "I-MIS, Miscellaneous entity\n",
    "\n",
    "B-PER, Beginning of a person's name right after another person's name\n",
    "\n",
    "I-PER, Person's name\n",
    "\n",
    "B-ORG, Beginning of an organisation right after another organisation\n",
    "\n",
    "I-ORG, Organisation\n",
    "\n",
    "B-LOC, Beginning of a location right after another location\n",
    "\n",
    "I-LOC, Location\n",
    "\n",
    "It leverages a fine-tuned model on CoNLL-2003, fine-tuned by @stefan-it from dbmdz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b46bd84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cb26c5592e241669d2f66ea696197af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/998 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd343da808404f1088779ccbc325baa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.24G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9954cceab1a4638a6ef493065ebb2be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/60.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c839ad3fa3ab485c902db70ebe154494",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/208k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "ner_pipe = pipeline(\"ner\")\n",
    "sequence = \"\"\"Hugging Face Inc. is a company based in New York City. Its headquarters are in DUMBO,\n",
    "therefore very close to the Manhattan Bridge which is visible from the window.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ed4cd7",
   "metadata": {},
   "source": [
    "This outputs a list of all words that have been identified as one of the entities from the 9 classes defined above. Here are the expected results:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053fca68",
   "metadata": {},
   "source": [
    "Note how the tokens of the sequence \"Hugging Face\" have been identified as an organisation, and \"New York City\", \"DUMBO\" and \"Manhattan Bridge\" have been identified as locations.\n",
    "\n",
    "Here is an example of doing named entity recognition, using a model and a tokenizer. The process is the following:\n",
    "\n",
    "1. Instantiate a tokenizer and a model from the checkpoint name. The model is identified as a BERT model and loads it with the weights stored in the checkpoint.\n",
    "\n",
    "2. Define a sequence with known entities, such as \"Hugging Face\" as an organisation and \"New York City\" as a location.\n",
    "\n",
    "3. Split words into tokens so that they can be mapped to predictions. We use a small hack by, first, completely encoding and decoding the sequence, so that we're left with a string that contains the special tokens.\n",
    "\n",
    "4. Encode that sequence into IDs (special tokens are added automatically).\n",
    "\n",
    "5. Retrieve the predictions by passing the input to the model and getting the first output. This results in a distribution over the 9 possible classes for each token. We take the argmax to retrieve the most likely class for each token.\n",
    "\n",
    "6. Zip together each token with its prediction and print it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "753a1187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f13518357c7f4372b02bd4a6eb96a15b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2ac57ba78aa483b997dca751d198fc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f42b559884fd4e16bf556b589d936cb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/208k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fbc2336db8148289959a6d35a4a2e1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/426k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## PYTORCH CODE\n",
    "from transformers import AutoModelForTokenClassification, AutoTokenizer\n",
    "import torch\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"dbmdz/bert-large-cased-finetuned-conll03-english\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "label_list = [\n",
    "    \"O\",       # Outside of a named entity\n",
    "    \"B-MISC\",  # Beginning of a miscellaneous entity right after another miscellaneous entity\n",
    "    \"I-MISC\",  # Miscellaneous entity\n",
    "    \"B-PER\",   # Beginning of a person's name right after another person's name\n",
    "    \"I-PER\",   # Person's name\n",
    "    \"B-ORG\",   # Beginning of an organisation right after another organisation\n",
    "    \"I-ORG\",   # Organisation\n",
    "    \"B-LOC\",   # Beginning of a location right after another location\n",
    "    \"I-LOC\"    # Location\n",
    "]\n",
    "sequence = \"Hugging Face Inc. is a company based in New York City. Its headquarters are in DUMBO, therefore very\" \\\n",
    "           \"close to the Manhattan Bridge.\"\n",
    "# Bit of a hack to get the tokens with the special tokens\n",
    "tokens = tokenizer.tokenize(tokenizer.decode(tokenizer.encode(sequence)))\n",
    "inputs = tokenizer.encode(sequence, return_tensors=\"pt\")\n",
    "outputs = model(inputs).logits\n",
    "predictions = torch.argmax(outputs, dim=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21f0603",
   "metadata": {},
   "source": [
    "This outputs a list of each token mapped to its corresponding prediction. Differently from the pipeline, here every token has a prediction as we didn't remove the \"0\"th class, which means that no particular entity was found on that token.\n",
    "\n",
    "In the above example, predictions is an integer that corresponds to the predicted class. We can use the model.config.id2label property in order to recover the class name corresponding to the class number, which is illustrated below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7659217b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('[CLS]', 'O')\n",
      "('Hu', 'I-ORG')\n",
      "('##gging', 'I-ORG')\n",
      "('Face', 'I-ORG')\n",
      "('Inc', 'I-ORG')\n",
      "('.', 'O')\n",
      "('is', 'O')\n",
      "('a', 'O')\n",
      "('company', 'O')\n",
      "('based', 'O')\n",
      "('in', 'O')\n",
      "('New', 'I-LOC')\n",
      "('York', 'I-LOC')\n",
      "('City', 'I-LOC')\n",
      "('.', 'O')\n",
      "('Its', 'O')\n",
      "('headquarters', 'O')\n",
      "('are', 'O')\n",
      "('in', 'O')\n",
      "('D', 'I-LOC')\n",
      "('##UM', 'I-LOC')\n",
      "('##BO', 'I-LOC')\n",
      "(',', 'O')\n",
      "('therefore', 'O')\n",
      "('very', 'O')\n",
      "('##c', 'O')\n",
      "('##lose', 'O')\n",
      "('to', 'O')\n",
      "('the', 'O')\n",
      "('Manhattan', 'I-LOC')\n",
      "('Bridge', 'I-LOC')\n",
      "('.', 'O')\n",
      "('[SEP]', 'O')\n"
     ]
    }
   ],
   "source": [
    "for token, prediction in zip(tokens, predictions[0].numpy()):\n",
    "    print((token, model.config.id2label[prediction]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16deea0e",
   "metadata": {},
   "source": [
    "# Summarization\n",
    "Summarization is the task of summarizing a document or an article into a shorter text. If you would like to fine-tune a model on a summarization task, you may leverage the run_summarization.py script.\n",
    "\n",
    "An example of a summarization dataset is the CNN / Daily Mail dataset, which consists of long news articles and was created for the task of summarization. If you would like to fine-tune a model on a summarization task, various approaches are described in this :prefix_link:document <examples/pytorch/summarization/README.md>.\n",
    "\n",
    "Here is an example of using the pipelines to do summarization. It leverages a Bart model that was fine-tuned on the CNN / Daily Mail data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d95f03c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 (https://huggingface.co/sshleifer/distilbart-cnn-12-6)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1fa3f9e114443d98001090663f59c36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.76k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0fc1d0c0e584300b636cd1dd8aa862f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.14G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cab1ebf433b4722be908ba88cf67812",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "708f7b662a6547b480221411a1666dc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7464c126aee94b2b8e04319b28974fb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "summarizer = pipeline(\"summarization\")\n",
    "ARTICLE = \"\"\" New York (CNN)When Liana Barrientos was 23 years old, she got married in Westchester County, New York.\n",
    "A year later, she got married again in Westchester County, but to a different man and without divorcing her first husband.\n",
    "Only 18 days after that marriage, she got hitched yet again. Then, Barrientos declared \"I do\" five more times, sometimes only within two weeks of each other.\n",
    "In 2010, she married once more, this time in the Bronx. In an application for a marriage license, she stated it was her \"first and only\" marriage.\n",
    "Barrientos, now 39, is facing two criminal counts of \"offering a false instrument for filing in the first degree,\" referring to her false statements on the\n",
    "2010 marriage license application, according to court documents.\n",
    "Prosecutors said the marriages were part of an immigration scam.\n",
    "On Friday, she pleaded not guilty at State Supreme Court in the Bronx, according to her attorney, Christopher Wright, who declined to comment further.\n",
    "After leaving court, Barrientos was arrested and charged with theft of service and criminal trespass for allegedly sneaking into the New York subway through an emergency exit, said Detective\n",
    "Annette Markowski, a police spokeswoman. In total, Barrientos has been married 10 times, with nine of her marriages occurring between 1999 and 2002.\n",
    "All occurred either in Westchester County, Long Island, New Jersey or the Bronx. She is believed to still be married to four men, and at one time, she was married to eight men at once, prosecutors say.\n",
    "Prosecutors said the immigration scam involved some of her husbands, who filed for permanent residence status shortly after the marriages.\n",
    "Any divorces happened only after such filings were approved. It was unclear whether any of the men will be prosecuted.\n",
    "The case was referred to the Bronx District Attorney\\'s Office by Immigration and Customs Enforcement and the Department of Homeland Security\\'s\n",
    "Investigation Division. Seven of the men are from so-called \"red-flagged\" countries, including Egypt, Turkey, Georgia, Pakistan and Mali.\n",
    "Her eighth husband, Rashid Rajput, was deported in 2006 to his native Pakistan after an investigation by the Joint Terrorism Task Force.\n",
    "If convicted, Barrientos faces up to four years in prison.  Her next court appearance is scheduled for May 18.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41da981",
   "metadata": {},
   "source": [
    "Because the summarization pipeline depends on the PreTrainedModel.generate() method, we can override the default arguments of PreTrainedModel.generate() directly in the pipeline for max_length and min_length as shown below. This outputs the following summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0b97506b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': ' Liana Barrientos, 39, is charged with two counts of \"offering a false instrument for filing in the first degree\" In total, she has been married 10 times, with nine of her marriages occurring between 1999 and 2002 . At one time, she was married to eight men at once, prosecutors say .'}]\n"
     ]
    }
   ],
   "source": [
    "print(summarizer(ARTICLE, max_length=130, min_length=30, do_sample=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79265548",
   "metadata": {},
   "source": [
    "Here is an example of doing summarization using a model and a tokenizer. The process is the following:\n",
    "\n",
    "1. Instantiate a tokenizer and a model from the checkpoint name. Summarization is usually done using an encoder-decoder model, such as Bart or T5.\n",
    "2. Define the article that should be summarized.\n",
    "3. Add the T5 specific prefix \"summarize: \".\n",
    "4. Use the PreTrainedModel.generate() method to generate the summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e02e7108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f6a8c9311b0401584afe0ab92e41780",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c54933e60284abdb801d428861b38e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/850M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a49010783430444aaf2107b63e77cd75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/773k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9939799d98474266b55f08e10c16383d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.32M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## PYTORCH CODE\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-base\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-base\")\n",
    "# T5 uses a max_length of 512 so we cut the article to 512 tokens.\n",
    "inputs = tokenizer.encode(\"summarize: \" + ARTICLE, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "outputs = model.generate(inputs, max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a2680644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> prosecutors say the marriages were part of an immigration scam. if convicted, barrientos faces two criminal counts of \"offering a false instrument for filing in the first degree\" she has been married 10 times, nine of them between 1999 and 2002.</s>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6496fd",
   "metadata": {},
   "source": [
    "# Translation\n",
    "Translation is the task of translating a text from one language to another. If you would like to fine-tune a model on a translation task, you may leverage the run_translation.py script.\n",
    "\n",
    "An example of a translation dataset is the WMT English to German dataset, which has sentences in English as the input data and the corresponding sentences in German as the target data. If you would like to fine-tune a model on a translation task, various approaches are described in this :prefix_link:*document\n",
    "\n",
    "<examples/pytorch.translation/README.md>*.\n",
    "\n",
    "Here is an example of using the pipelines to do translation. It leverages a T5 model that was only pre-trained on a multi-task mixture dataset (including WMT), yet, yielding impressive translation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a7f9879e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to t5-base (https://huggingface.co/t5-base)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'translation_text': 'Hugging Face ist ein Technologieunternehmen mit Sitz in New York und Paris.'}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "translator = pipeline(\"translation_en_to_de\")\n",
    "print(translator(\"Hugging Face is a technology company based in New York and Paris\", max_length=40))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6ab1f6",
   "metadata": {},
   "source": [
    "Because the translation pipeline depends on the PreTrainedModel.generate() method, we can override the default arguments of PreTrainedModel.generate() directly in the pipeline as is shown for max_length above.\n",
    "\n",
    "Here is an example of doing translation using a model and a tokenizer. The process is the following:\n",
    "\n",
    "1. Instantiate a tokenizer and a model from the checkpoint name. Summarization is usually done using an encoder-decoder model, such as Bart or T5.\n",
    "\n",
    "2. Define the article that should be summarized.\n",
    "\n",
    "3. Add the T5 specific prefix \"translate English to German: \"\n",
    "\n",
    "4. Use the PreTrainedModel.generate() method to perform the translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b3b117d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PYTORCH CODE\n",
    "from transformers import AutoModelWithLMHead, AutoTokenizer\n",
    "model = AutoModelWithLMHead.from_pretrained(\"t5-base\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-base\")\n",
    "inputs = tokenizer.encode(\"translate English to German: Hugging Face is a technology company based in New York and Paris\", return_tensors=\"pt\")\n",
    "outputs = model.generate(inputs, max_length=40, num_beams=4, early_stopping=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd78ccd",
   "metadata": {},
   "source": [
    "As with the pipeline example, we get the same translation:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e4018327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> Hugging Face ist ein Technologieunternehmen mit Sitz in New York und Paris.</s>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a989606",
   "metadata": {},
   "source": [
    "# Preprocessing data\n",
    "In this tutorial, we'll explore how to preprocess your data using ðŸ¤— Transformers. The main tool for this is what we call a tokenizer. You can build one using the tokenizer class associated to the model you would like to use, or directly with the AutoTokenizer class.\n",
    "\n",
    "As we saw in the quick tour, the tokenizer will first split a given text in words (or part of words, punctuation symbols, etc.) usually called tokens. Then it will convert those tokens into numbers, to be able to build a tensor out of them and feed them to the model. It will also add any additional inputs the model might expect to work properly.\n",
    "\n",
    "NOTE: If you plan on using a pretrained model, it's important to use the associated pretrained tokenizer: it will split the text you give it in tokens the same way for the pretraining corpus, and it will use the same correspondence token to index (that we usually call a vocab) as during pretraining.\n",
    "\n",
    "To automatically download the vocab used during pretraining or fine-tuning a given model, you can use the AutoTokenizer.from_pretrained method:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f3eefd",
   "metadata": {},
   "source": [
    "#### Base use\n",
    "A PreTrainedTokenizer has many methods, but the only one you need to remember for preprocessing is its __call__: you just need to feed your sentence to your tokenizer object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c8328205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [8774, 6, 27, 31, 51, 3, 9, 712, 7142, 55, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "encoded_input = tokenizer(\"Hello, I'm a single sentence!\")\n",
    "print(encoded_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff1a3c2",
   "metadata": {},
   "source": [
    "This returns a dictionary string to list of ints. The input_ids are the indices corresponding to each token in our sentence. We will see below what the attention_mask is used for and in the next section the goal of token_type_ids.\n",
    "\n",
    "The tokenizer can decode a list of token ids in a proper sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "38774891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello, I'm a single sentence!</s>\""
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(encoded_input[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8c22f3",
   "metadata": {},
   "source": [
    "As you can see, the tokenizer automatically added some special tokens that the model expects. Not all models need special tokens; for instance, if we had used gpt2-medium instead of bert-base-cased to create our tokenizer, we would have seen the same sentence as the original one here. You can disable this behavior (which is only advised if you have added those special tokens yourself) by passing add_special_tokens=False.\n",
    "\n",
    "If you have several sentences you want to process, you can do this efficiently by sending them as a list to the tokenizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "75a47933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [[8774, 27, 31, 51, 3, 9, 712, 7142, 1], [275, 430, 7142, 1], [275, 8, 182, 182, 336, 80, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1]]}\n"
     ]
    }
   ],
   "source": [
    "batch_sentences = [\"Hello I'm a single sentence\",\n",
    "                   \"And another sentence\",\n",
    "                   \"And the very very last one\"]\n",
    "encoded_inputs = tokenizer(batch_sentences)\n",
    "print(encoded_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e6dd39",
   "metadata": {},
   "source": [
    "We get back a dictionary once again, this time with values being lists of lists of ints.\n",
    "\n",
    "If the purpose of sending several sentences at a time to the tokenizer is to build a batch to feed the model, you will probably want:\n",
    "\n",
    "1. To pad each sentence to the maximum length there is in your batch.\n",
    "\n",
    "2. To truncate each sentence to the maximum length the model can accept (if applicable).\n",
    "\n",
    "3. To return tensors.\n",
    "\n",
    "You can do all of this by using the following options when feeding your list of sentences to the tokenizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1ed12631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[8774,   27,   31,   51,    3,    9,  712, 7142,    1],\n",
      "        [ 275,  430, 7142,    1,    0,    0,    0,    0,    0],\n",
      "        [ 275,    8,  182,  182,  336,   80,    1,    0,    0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0]])}\n"
     ]
    }
   ],
   "source": [
    "## PYTORCH CODE\n",
    "batch = tokenizer(batch_sentences, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c842b9a",
   "metadata": {},
   "source": [
    "It returns a dictionary with string keys and tensor values. We can now see what the attention_mask is all about: it points out which tokens the model should pay attention to and which ones it should not (because they represent padding in this case).\n",
    "\n",
    "Note that if your model does not have a maximum length associated to it, the command above will throw a warning. You can safely ignore it. You can also pass verbose=False to stop the tokenizer from throwing those kinds of warnings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6502f36d",
   "metadata": {},
   "source": [
    "# Preprocessing pairs of sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6fc84c",
   "metadata": {},
   "source": [
    "Sometimes you need to feed a pair of sentences to your model. For instance, if you want to classify if two sentences in a pair are similar, or for question-answering models, which take a context and a question. For BERT models, the input is then represented like this:\n",
    "- [CLS] Sequence A [SEP] Sequence B [SEP]\n",
    "\n",
    "You can encode a ***pair of sentences*** in the format expected by your model ***by supplying the two sentences as two arguments*** (***not a list since a list of two sentences will be interpreted as a batch of two single sentences, as we saw before***). This will once again return a dict string to list of ints:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6c30b247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [571, 625, 33, 25, 58, 1, 27, 31, 51, 431, 203, 625, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "encoded_input = tokenizer(\"How old are you?\", \"I'm 6 years old\")\n",
    "print(encoded_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fce5bb",
   "metadata": {},
   "source": [
    "If we decode the token ids we obtained, we will see that the special tokens have been properly added.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fcc21c34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"How old are you?</s> I'm 6 years old</s>\""
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(encoded_input[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa752f0",
   "metadata": {},
   "source": [
    "If you have a list of pairs of sequences you want to process, you should feed them as two lists to your tokenizer: the list of first sentences and the list of second sentences:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "47d6fd57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [[8774, 27, 31, 51, 3, 9, 712, 7142, 1, 27, 31, 51, 3, 9, 7142, 24, 1550, 28, 8, 166, 7142, 1], [275, 430, 7142, 1, 275, 27, 225, 36, 23734, 26, 28, 8, 511, 7142, 1], [275, 8, 182, 182, 336, 80, 1, 275, 27, 281, 28, 8, 182, 336, 80, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"
     ]
    }
   ],
   "source": [
    "batch_sentences = [\"Hello I'm a single sentence\",\n",
    "                   \"And another sentence\",\n",
    "                   \"And the very very last one\"]\n",
    "batch_of_second_sentences = [\"I'm a sentence that goes with the first sentence\",\n",
    "                             \"And I should be encoded with the second sentence\",\n",
    "                             \"And I go with the very last one\"]\n",
    "encoded_inputs = tokenizer(batch_sentences, batch_of_second_sentences)\n",
    "print(encoded_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1834f098",
   "metadata": {},
   "source": [
    "As we can see, it returns a dictionary where each value is a list of lists of ints.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56634b43",
   "metadata": {},
   "source": [
    "To double-check what is fed to the model, we can decode each list in input_ids one by one:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "75f11991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello I'm a single sentence</s> I'm a sentence that goes with the first sentence</s>\n",
      "And another sentence</s> And I should be encoded with the second sentence</s>\n",
      "And the very very last one</s> And I go with the very last one</s>\n"
     ]
    }
   ],
   "source": [
    "for ids in encoded_inputs[\"input_ids\"]:\n",
    "    print(tokenizer.decode(ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225326bd",
   "metadata": {},
   "source": [
    "Once again, you can automatically pad your inputs to the maximum sentence length in the batch, truncate to the maximum length the model can accept and return tensors directly with the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "de1640bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PYTORCH CODE\n",
    "batch = tokenizer(batch_sentences, batch_of_second_sentences, padding=True, truncation=True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8262bbd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[ 8774,    27,    31,    51,     3,     9,   712,  7142,     1,    27,\n",
      "            31,    51,     3,     9,  7142,    24,  1550,    28,     8,   166,\n",
      "          7142,     1],\n",
      "        [  275,   430,  7142,     1,   275,    27,   225,    36, 23734,    26,\n",
      "            28,     8,   511,  7142,     1,     0,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  275,     8,   182,   182,   336,    80,     1,   275,    27,   281,\n",
      "            28,     8,   182,   336,    80,     1,     0,     0,     0,     0,\n",
      "             0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]])}\n"
     ]
    }
   ],
   "source": [
    "print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541176a0",
   "metadata": {},
   "source": [
    "# Everything you always wanted to know about padding and truncation\n",
    "We have seen the commands that will work for most cases (pad your batch to the length of the maximum sentence and truncate to the maximum length the mode can accept). However, the API supports more strategies if you need them. The three arguments you need to know for this are padding, truncation and max_length."
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "3d7b35c8",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23025c32",
   "metadata": {},
   "source": [
    "# Fine-tuning a pretrained model\n",
    "In this tutorial, we will show you how to fine-tune a pretrained model from the Transformers library. In TensorFlow, models can be directly trained using Keras and the fit method. In PyTorch, there is no generic training loop so the ðŸ¤— Transformers library provides an API with the class Trainer to let you fine-tune or train a model from scratch easily. Then we will show you how to alternatively write the whole training loop in PyTorch.\n",
    "\n",
    "Before we can fine-tune a model, we need a dataset. In this tutorial, we will show you how to fine-tune BERT on the IMDB dataset: the task is to classify whether movie reviews are positive or negative. For examples of other tasks, refer to the additional-resources section!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d22a324",
   "metadata": {},
   "source": [
    "# Preparing the datasets\n",
    "We will use the ðŸ¤— Datasets library to download and preprocess the IMDB datasets. We will go over this part pretty quickly. Since the focus of this tutorial is on training, you should refer to the ðŸ¤— Datasets documentation or the preprocessing tutorial for more information.\n",
    "\n",
    "First, we can use the load_dataset function to download and cache the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5ffd644c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset imdb (C:\\Users\\Naim Cavin\\.cache\\huggingface\\datasets\\imdb\\plain_text\\1.0.0\\e3c66f1788a67a89c7058d97ff62b6c30531e05b549de56d3ab91891f0561f9a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d8f18030501444995210eceddd928d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "raw_datasets = load_dataset(\"imdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5821040e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    unsupervised: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f938f4",
   "metadata": {},
   "source": [
    "This works like the from_pretrained method we saw for the models and tokenizers (except the cache directory is ~/.cache/huggingface/dataset by default).\n",
    "\n",
    "The raw_datasets object is a dictionary with three keys: \"train\", \"test\" and \"unsupervised\" (which correspond to the three splits of that dataset). We will use the \"train\" split for training and the \"test\" split for validation.\n",
    "\n",
    "To preprocess our data, we will need a tokenizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "04ac0520",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at C:\\Users\\Naim Cavin/.cache\\huggingface\\transformers\\a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.12.5\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/bert-base-cased/resolve/main/vocab.txt from cache at C:\\Users\\Naim Cavin/.cache\\huggingface\\transformers\\6508e60ab3c1200bffa26c95f4b58ac6b6d95fba4db1f195f632fa3cd7bc64cc.437aa611e89f6fc6675a049d2b5545390adbc617e7d655286421c191d2be2791\n",
      "loading file https://huggingface.co/bert-base-cased/resolve/main/tokenizer.json from cache at C:\\Users\\Naim Cavin/.cache\\huggingface\\transformers\\226a307193a9f4344264cdc76a12988448a25345ba172f2c7421f3b6810fddad.3dab63143af66769bbb35e3811f75f7e16b2320e12b7935e216bd6159ce6d9a6\n",
      "loading file https://huggingface.co/bert-base-cased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-cased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-cased/resolve/main/tokenizer_config.json from cache at C:\\Users\\Naim Cavin/.cache\\huggingface\\transformers\\ec84e86ee39bfe112543192cf981deebf7e6cbe8c91b8f7f8f63c9be44366158.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n",
      "loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at C:\\Users\\Naim Cavin/.cache\\huggingface\\transformers\\a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.12.5\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cceaae",
   "metadata": {},
   "source": [
    "As we saw in preprocessing, we can prepare the text inputs for the model with the following command (this is an example, not a command you can execute):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "dc935508",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FOR EXAMPLE: inputs = tokenizer(sentences, padding=\"max_length\", truncation=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e2b7e4",
   "metadata": {},
   "source": [
    "This will make all the samples have the maximum length the model can accept (here 512), either by padding or truncating them.\n",
    "\n",
    "However, we can instead apply these preprocessing steps to all the splits of our dataset at once by using the ***map*** method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ddcb6e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\Naim Cavin\\.cache\\huggingface\\datasets\\imdb\\plain_text\\1.0.0\\e3c66f1788a67a89c7058d97ff62b6c30531e05b549de56d3ab91891f0561f9a\\cache-97a9b41f0f819498.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7be5eb06ac174e118bc96049bdf4a34d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\Naim Cavin\\.cache\\huggingface\\datasets\\imdb\\plain_text\\1.0.0\\e3c66f1788a67a89c7058d97ff62b6c30531e05b549de56d3ab91891f0561f9a\\cache-d9199123f4034b0b.arrow\n"
     ]
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563006e0",
   "metadata": {},
   "source": [
    "Next we will generate a small subset of the training and validation set, to enable faster training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c5836626",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at C:\\Users\\Naim Cavin\\.cache\\huggingface\\datasets\\imdb\\plain_text\\1.0.0\\e3c66f1788a67a89c7058d97ff62b6c30531e05b549de56d3ab91891f0561f9a\\cache-bbe2e20f27131cb8.arrow\n"
     ]
    }
   ],
   "source": [
    "small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(1000)) \n",
    "small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(1000)) \n",
    "full_train_dataset = tokenized_datasets[\"train\"]\n",
    "full_eval_dataset = tokenized_datasets[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81fbccd",
   "metadata": {},
   "source": [
    "In all the examples below, we will always use small_train_dataset and small_eval_dataset. Just replace them by their full equivalent to train or evaluate on the full dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d78baa",
   "metadata": {},
   "source": [
    "# Fine-tuning in PyTorch with the Trainer API\n",
    "\n",
    "Since PyTorch does not provide a training loop, the ðŸ¤— Transformers library provides a ***Trainer*** API that is optimized for ðŸ¤— Transformers models, with a wide range of training options and with built-in features like logging, gradient accumulation, and mixed precision.\n",
    "\n",
    "First, let's define our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5d2f5108",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at C:\\Users\\Naim Cavin/.cache\\huggingface\\transformers\\a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.12.5\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-cased/resolve/main/pytorch_model.bin from cache at C:\\Users\\Naim Cavin/.cache\\huggingface\\transformers\\092cc582560fc3833e556b3f833695c26343cb54b7e88cd02d40821462a74999.1f48cab6c959fc6c360d22bea39d06959e90f5b002e77e836d2da45464875cda\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f7d83d",
   "metadata": {},
   "source": [
    "This will issue a warning about some of the pretrained weights not being used and some weights being randomly initialized. That's because we are throwing away the pretraining head of the BERT model to replace it with a classification head which is randomly initialized. We will fine-tune this model on our task, transferring the knowledge of the pretrained model to it (which is why doing ***this is called transfer learning***)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1de92f",
   "metadata": {},
   "source": [
    "Then, to define our ***Trainer***, we will need to instantiate a ***TrainingArguments***. This class contains all the hyperparameters we can tune for the ***Trainer*** or the flags to activate the different training options it supports. Let's begin by using all the defaults, the only thing we then have to provide is a directory in which the checkpoints will be saved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f0fcef04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\"test_trainer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1d1ab27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\"test_trainer\",per_device_eval_batch_size=4,\n",
    "per_device_train_batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "76740e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_find_unused_parameters=None,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=False,\n",
      "eval_accumulation_steps=None,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=IntervalStrategy.NO,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "hub_model_id=None,\n",
      "hub_strategy=HubStrategy.EVERY_SAVE,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=5e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=-1,\n",
      "log_level_replica=-1,\n",
      "log_on_each_node=True,\n",
      "logging_dir=test_trainer\\runs\\Nov20_21-18-09_MSI,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=500,\n",
      "logging_strategy=IntervalStrategy.STEPS,\n",
      "lr_scheduler_type=SchedulerType.LINEAR,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3.0,\n",
      "output_dir=test_trainer,\n",
      "overwrite_output_dir=False,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=4,\n",
      "per_device_train_batch_size=4,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=test_trainer,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=IntervalStrategy.STEPS,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_legacy_prediction_loop=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(training_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cee8e35",
   "metadata": {},
   "source": [
    "Then we can instantiate a ***Trainer*** like this:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "607093ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model, args=training_args, train_dataset=small_train_dataset, eval_dataset=small_eval_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1da7b62",
   "metadata": {},
   "source": [
    "To fine-tune our model, we just need to call\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef5b925",
   "metadata": {},
   "source": [
    "we will want to use the GPU if we have access to one (otherwise training might take several hours instead of a couple of minutes). To do this, we define a device we will put our model and our batches on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9df9fbbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3c728320",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running training *****\n",
      "  Num examples = 1000\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 750\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-114-3435b262f1ae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1314\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1316\u001b[1;33m                     \u001b[0mtr_loss_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m                 if (\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[1;34m(self, model, inputs)\u001b[0m\n\u001b[0;32m   1865\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeepspeed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1866\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1867\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1868\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1869\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 307\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 154\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c035b4f0",
   "metadata": {},
   "source": [
    "which will start a training that you can follow with a progress bar, which should take a couple of minutes to complete (as long as you have access to a GPU). It won't actually tell you anything useful about how well (or badly) your model is performing however as by default, there is no evaluation during training, and we didn't tell the Trainer to compute any metrics. Let's have a look on how to do that now!\n",
    "\n",
    "To have the ***Trainer*** compute and report metrics, we need to give it a ***compute_metrics*** function that takes predictions and labels (grouped in a namedtuple called EvalPrediction) and return a dictionary with string items (the metric names) and float values (the metric values).\n",
    "\n",
    "The ðŸ¤— Datasets library provides an easy way to get the common metrics used in NLP with the ***load_metric*** function. here we simply use accuracy. Then we define the ***compute_metrics*** function that just convert logits to predictions (remember that all ðŸ¤— Transformers models return the logits) and feed them to compute method of this metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "2e2525d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85e08a7ff4fc42fcb60ed4a29f480148",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.42k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "\n",
    "metric = load_metric(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20b19fe",
   "metadata": {},
   "source": [
    "The compute function needs to receive a tuple (with logits and labels) and has to return a dictionary with string keys (the name of the metric) and float values. It will be called at the end of each evaluation phase on the whole arrays of predictions/labels.\n",
    "\n",
    "To check if this works on practice, let's create a new ***Trainer*** with our fine-tuned model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "31e3faba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [250/250 02:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.7652339339256287,\n",
       " 'eval_accuracy': 0.512,\n",
       " 'eval_runtime': 131.9164,\n",
       " 'eval_samples_per_second': 7.581,\n",
       " 'eval_steps_per_second': 1.895}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=small_train_dataset,\n",
    "    eval_dataset=small_eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bc5335",
   "metadata": {},
   "source": [
    "which showed an ***accuracy of 51.5%*** in our case. But I decresed the num_batch size from 8 to 4.\n",
    "\n",
    "If you want to fine-tune your model and regularly report the evaluation metrics (for instance at the end of each epoch), here is how you should define your training arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "7ad83a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\"test_trainer\", evaluation_strategy=\"epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4524c1d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "07e50232",
   "metadata": {},
   "source": [
    "# Fine-tuning in native PyTorch\n",
    "RAW HTML:\n",
    "\n",
    "You might need to restart your notebook at this stage to free some memory, or excute the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa5d698",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "del pytorch_model\n",
    "del trainer\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd9ff4a",
   "metadata": {},
   "source": [
    "Let's now see how to achieve the same results as in trainer section in PyTorch. First we need to define the dataloaders, which we will use to iterate over batches. We just need to apply a bit of post-processing to our tokenized_datasets before doing that to:\n",
    "\n",
    "1. remove the columns corresponding to values the model does not expect (here the \"text\" column)\n",
    "\n",
    "2. rename the column \"label\" to \"labels\" (because the model expect the argument to be named labels)\n",
    "\n",
    "3. set the format of the datasets so they return PyTorch Tensors instead of lists.\n",
    "\n",
    "Our tokenized_datasets has one method for each of those steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "5e7d1946",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = tokenized_datasets.remove_columns([\"text\"])\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "\n",
    "small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(1000))\n",
    "small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9008755",
   "metadata": {},
   "source": [
    "Now that this is done, we can easily define our dataloaders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "26981f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(small_train_dataset, shuffle=True, batch_size=8)\n",
    "eval_dataloader = DataLoader(small_eval_dataset, batch_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641ab57a",
   "metadata": {},
   "source": [
    "Next, we define our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "0e15826c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at C:\\Users\\Naim Cavin/.cache\\huggingface\\transformers\\a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.12.5\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-cased/resolve/main/pytorch_model.bin from cache at C:\\Users\\Naim Cavin/.cache\\huggingface\\transformers\\092cc582560fc3833e556b3f833695c26343cb54b7e88cd02d40821462a74999.1f48cab6c959fc6c360d22bea39d06959e90f5b002e77e836d2da45464875cda\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941497aa",
   "metadata": {},
   "source": [
    "We are almost ready to write our training loop, the only two things are missing are an optimizer and a learning rate scheduler. The default optimizer used by the ***Trainer is AdamW***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a7ae2533",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951eb4d6",
   "metadata": {},
   "source": [
    "Finally, the learning rate scheduler used by default it just a linear decay form the maximum value (5e-5 here) to 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ff661642",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_scheduler\n",
    "\n",
    "num_epochs = 3\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45efdf0f",
   "metadata": {},
   "source": [
    "One last thing, we will want to use the GPU if we have access to one (otherwise training might take several hours instead of a couple of minutes). To do this, we define a device we will put our model and our batches on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "fc97bce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f2dda5",
   "metadata": {},
   "source": [
    "We now are ready to train! To get some sense of when it will be finished, we add a progress bar over our number of training steps, using the tqdm library.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "635181f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6efdce13b0e4f72a5e1039045216db8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 6.00 GiB total capacity; 4.69 GiB already allocated; 0 bytes free; 4.76 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-125-b86b10a2f8e7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1118\u001b[0m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbw_hook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetup_input_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1120\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1121\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_global_forward_hooks\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1528\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1529\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1530\u001b[1;33m         outputs = self.bert(\n\u001b[0m\u001b[0;32m   1531\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1532\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1118\u001b[0m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbw_hook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetup_input_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1120\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1121\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_global_forward_hooks\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    994\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    995\u001b[0m         )\n\u001b[1;32m--> 996\u001b[1;33m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[0;32m    997\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    998\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    581\u001b[0m                 )\n\u001b[0;32m    582\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 583\u001b[1;33m                 layer_outputs = layer_module(\n\u001b[0m\u001b[0;32m    584\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    509\u001b[0m             \u001b[0mpresent_key_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpresent_key_value\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcross_attn_present_key_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m         layer_output = apply_chunking_to_forward(\n\u001b[0m\u001b[0;32m    512\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\modeling_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[1;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[0;32m   2358\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2360\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[1;34m(self, attention_output)\u001b[0m\n\u001b[0;32m    521\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    522\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 523\u001b[1;33m         \u001b[0mintermediate_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    524\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    525\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states)\u001b[0m\n\u001b[0;32m    423\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 425\u001b[1;33m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintermediate_act_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    426\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mgelu\u001b[1;34m(input)\u001b[0m\n\u001b[0;32m   1554\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhas_torch_function_unary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1555\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgelu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1556\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1557\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1558\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 6.00 GiB total capacity; 4.69 GiB already allocated; 0 bytes free; 4.76 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in train_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bbe407",
   "metadata": {},
   "source": [
    "Note that if you are used to freezing the body of your pretrained model (like in computer vision) the above may seem a bit strange, as we are directly fine-tuning the whole model without taking any precaution. It actually works better this way for Transformers model (so this is not an oversight on our side). If you're not familiar with what \"freezing the body\" of the model means, forget you read this paragraph.\n",
    "\n",
    "Now to check the results, we need to write the evaluation loop. Like in the trainer section we will use a metric from the datasets library. Here we accumulate the predictions at each batch before computing the final result when the loop is finished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a83252bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 6.00 GiB total capacity; 4.72 GiB already allocated; 0 bytes free; 4.76 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-126-b4b542d3d59d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1528\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1529\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1530\u001b[1;33m         outputs = self.bert(\n\u001b[0m\u001b[0;32m   1531\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1532\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    987\u001b[0m         \u001b[0mhead_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_head_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 989\u001b[1;33m         embedding_output = self.embeddings(\n\u001b[0m\u001b[0;32m    990\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    991\u001b[0m             \u001b[0mposition_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[0mtoken_type_embeddings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoken_type_embeddings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m         \u001b[0membeddings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtoken_type_embeddings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    218\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposition_embedding_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"absolute\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m             \u001b[0mposition_embeddings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposition_embeddings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 6.00 GiB total capacity; 4.72 GiB already allocated; 0 bytes free; 4.76 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "metric= load_metric(\"accuracy\")\n",
    "model.eval()\n",
    "for batch in eval_dataloader:\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "\n",
    "metric.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9c92af",
   "metadata": {},
   "source": [
    "# Summary of the tokenizers\n",
    "On this page, we will have a closer look at tokenization.\n",
    "\n",
    "As we saw in the preprocessing tutorial, tokenizing a text is splitting it into words or subwords, which then are converted to ids through a look-up table. Converting words or subwords to ids is straightforward, so in this summary, we will focus on splitting a text into words or subwords (i.e. tokenizing a text). More specifically, ***we will look at the three main types of tokenizers used in ðŸ¤— Transformers: Byte-Pair Encoding (BPE), WordPiece, and SentencePiece***, and show examples of which tokenizer type is used by which model.\n",
    "\n",
    "Note that on each model page, you can look at the documentation of the associated tokenizer to know which tokenizer type was used by the pretrained model. For instance, if we look at ***BertTokenizer, we can see that the model uses WordPiece***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8918cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
